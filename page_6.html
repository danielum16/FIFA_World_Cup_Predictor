<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../../../favicon.ico"> -->

    <title>Group 25</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    <style>
        .col-centered {
            margin: 0 auto;
            float: none;
        }
    </style>
    <link rel="stylesheet" href="css/atom-one-light.css">
  </head>

  <body>
    <div class="container" style="margin-top:25px;">
    <div class="row">
    <div class="col-md-10 col-centered">
        <nav style="margin-bottom: 25px;">
            <a href="index.html">Background and Motivation</a>
            &nbsp;|&nbsp;<a href="page_2.html">Introduction and EDA</a>
            &nbsp;|&nbsp;<a href="page_3.html">Literature Review</a>
            &nbsp;|&nbsp;<a href="page_4.html">Models</a>
            &nbsp;|&nbsp;<a href="page_5.html">Results and Conclusion</a>
            &nbsp;|&nbsp;<span>Summary</span>
        </nav>

      <h1>Summary</h1>
      <p class="lead">Crafting a Summary Narrative of our Analysis</p>

      <hr>

      <h4>Contents</h4>
      <ol>
          <a href="#One"><li>Intro/Background about World Cup</li></a>
          <a href="#Two"><li>Motivation for predicting the World Cup</li></a>
          <a href="#Three"><li>Description of Initial Data (including cleansing procedures)</li></a>
          <a href="#Four"><li>Baseline models (created with the above datasets)</li></a>
          <a href="#Five"><li>Interesting Investigations/Additional features + EDA</li></a>
          <a href="#Six"><li>Improved Models</li></a>
          <a href="#Seven"><li>Best Model</li></a>
          <a href="#Eight"><li>Final Analysis, Conclusion, and Future Directions</li></a>
          <a href="#Nine"><li>Results (for reference)</li></a>
      </ol>

      <hr>

      <h2 id="One">Intro/Background about World Cup</h2>

      <br/>

      <p>The World Cup is the most prominent sporting event in the world, with over 1 billion people tuning in. The bare-bones nature of soccer allows for it to be easily understood and adopted, allows for it to be played by almost anyone (regardless of socioeconomic background), and it’s exciting atmosphere allows for it to be enjoyed by all. The World Cup has become a worldwide cultural phenomenon and the stakes to win are high; the winning nation receives a great deal of international fame and prestige. Recently, the World Cup has been growing in international recognition and viewership, and even though the World Cup has garnered such a huge viewer-base, the state of analytics on the World Cup (and soccer, in general) matches is archaic, relative to other sports such as Basketball and American Football. Soccer and World Cup analytics are on the rise, however, within the scope of this project, we aimed to make a prediction model (which we were able to complete), to contribute to these analytics even further.</p>

      <hr>

      <h2 id="Two">Motivation for predicting the World Cup</h2>

      <br/>

      <p>Shiv is an avid soccer player and Daniel, although he doesn’t play soccer, follows professional and college soccer enthusiastically. Krupesh is also very interested in sports statistics and regularly plays fantasy sports like NFL and Cricket. Pegah is also a fan of soccer and has been following 2018 World Cup with such passion. We would love to delve into the world of sports analytics, and become more informed on how professional statisticians ‘conjure-up’ their predictions, while also learning why many of their guesses fail. We are excited to dig-into the many grey-area factors that are often overlooked by common World Cup match predictions and (hopefully) create a great model that creates accurate predictions and allows us to impress our friends at future World Cup viewing parties.</p>

      <hr>

      <h2 id="Three">Description of Initial Data (including cleansing procedures)</h2>

      <br/>

      <p>The first provided dataset consisted of player statistics from 17994 current professional soccer players, representing 190 countries. It included numerical variables such as overall score and potential, but also categorical variables such as league, and nationality. The second provided dataset consisted of head-to-head matchups between national countries that gave the venue location, the name of the home and away team, and the number of goals for each team.The third dataset was a FIFA ranking dataset that ranks all of the national soccer teams by points.  To clean them, and use them as feature sets, we just averaged the player statistics by country, and plugged them into the head-to-head dataset.</p>

      <hr>

      <h2 id="Four">Baseline models (created with the above datasets)</h2>

      <br/>

      <p>We constructed two baseline models that incorporated features from the aforementioned given datasets. We constructed the feature set for these baseline models by aggregating the player statistics for each country, and then replacing these country statistics for the country name in the head-to-head dataset. We then performed an 80-20 train-test-split, to train both models. The first model was a W/L/D classification model achieved a meager 48% test set classification accuracy. We used logistic regression as a classification model architecture and used the gridsearchCV method provided by sklearn to tune the hyperparameters. The response variable in this model’s case was whether the home team won, drew, or lost to the away team. The second baseline model was a Goal Differential regression model which achieved a similarly poor r^2 score of 0.04. We used linear regression as a regression model architecture and again used gridsearchCV to tune the hyperparameters. The response variable was the score difference between the home and away team. We didn’t use the expected points baseline model, because we felt that one classification and one regression model would be enough to differentiate between.</p>

      <hr>

      <h2 id="Five">Interesting Investigations/Additional features + EDA</h2>

      <br/>

      <p>With our bare-bones models completed, we began to scrape and analyze new feature to enrich our feature set. First, we explored the truth of the home-country advantage, finding that it was extremely prevalent, especially in areas with low official regulation. In addition, generalized the home-country advantage by confederation, and found South America and Africa to have the biggest home-country advantages. We were able to model these and neutral-site advantages, by using a Poisson helper model, which modeled the distribution in home and away team goals in different countries.</p>

      <img class="img-fluid" src="images/HomeAwayMain.png">
      <p></p>
<!--       <br/> -->

      <p>We then scraped game-day statistics such as elevation, longitude, and latitude of the stadium that the match was being held at. After our EDA, we found that elevation played the most important role in the outcome of the match, and seems to have a somewhat linear correlation.</p>

      <img class="img-fluid" src="images/Location1.png">
      <p></p>
<!--       <br/> -->

      <p>Next, we examined the so-called “Champion’s Curse”, which we found to be a very important factor. Only 2 of the 21 previous winners of the World Cup have won the world cup twice consecutively, while the rest have done relatively poorly, showing that there is a clear Winner’s Disadvantage.</p>

      <img class="img-fluid" src="images/Curse1.png">
      <p></p>
<!--       <br/> -->

      <p>Next, we examined the so-called “Champion’s Curse”, which we found to be a very important factor. Only 2 of the 21 previous winners of the World Cup have won the world cup twice consecutively, while the rest have done relatively poorly, showing that there is a clear Winner’s Disadvantage.</p>

      <img class="img-fluid" src="images/Wealth4_new.png">

      <hr>

      <h2 id="Six">Improved Models</h2>

      <br/>

      <p>We proceeded to improve upon our baseline models by re-running our baseline models with this expanded feature set: Our classification model achieved a test classification accuracy of 55%, while the regression model achieved an r^2 score of 0.19. We improved 7% in the classification model test set classification accuracy and 0.15 in the regression model r^2 score. We determined that the all of the predictors were important in both of the models through stepwise visualizations.</p>

      <hr>

      <h2 id="Seven">Best Model</h2>

      <br/>

      <p>While these improvements were major, we still feel that the results didn’t improve upon the predictive power of the models found in the literature, so there was still another step to go. In this final model, we aimed to find the best model architecture and hyperparameters to optimize performance on our expanded feature set. After consulting the literature (and Patrick) and then performing lots and lot of cross-validation, we found that a Random Forest Model with a length of 5 performed the best, achieving a test classification accuracy of 61.5% for the classification model. In this final model, we were able to exclude FIFA ratings as a predictor, making it even more robust on the World Cup 2018 dataset (which we used as a test set), where it predicted the outcomes of 40 out of the 64 matches correctly!</p>
      
      <hr>

      <h2 id="Eight">Final Analysis, Conclusion, and Future Directions</h2>

      <br/>

      <p>In this project, we were able to create a final prediction model with State-of-the art predictive power, by building off of previous work that had been done in the field, as well as creating a large feature set of relevant and significant features, and utilizing the optimal architecture and hyperparameters (Random Forest classifier with a depth of 5). Impressively, our model was able to predict the outcome (win/loss/draw) of 40 out of the 64 total World Cup Matches in 2018, using the 32-feature expanded feature set we created! Interestingly, we found that this classification method was more accurate than the goal difference method, while training on the same data. This is most likely because the goal difference model almost never predicted exactly 0, so the number of draws was dramatically reduced. We were able to fix this (to some extent) by increasing the range of draw values, but still preferred the classification model because of its simplicity in interpretation. </p>

      <p>As always, the future extension of work is to find and model even more externalities that affect the outcomes of these world cup matches. This goes hand-in-hand with gaining more domain knowledge and including more relevant predictors. Thus, our future work will mainly be diving deeper into two areas: relevant feature-set expansion, and model selection. In retrospect, this was a fantastic introduction to a real-life application to data science. It was not only informative and a great learning experience, but it was also really fun! Group 25 would like to thank Patrick especially, for all of the time and effort he has put into our group to make sure that our project was smooth and successful.</p>
      
      <hr>

      <h2 id="Nine">Results (for reference)</h2>

      <br/>

      <h4>Goal Difference (Baseline Model)</h4>

      <p>Training r^2 score: 0.09</p>
      <p>Test r^2 score: 0.04</p>

      <h4>Win/Loss/Draw (Baseline Model)</h4>

      <p>Training Classification Accuracy: 51%</p>
      <p>Test Classification Accuracy: 48%</p>

      <h4>Goal Difference (Improved Model)</h4>

      <p>Training r^2 score: 0.32</p>
      <p>Test r^2 score: 0.019</p>

      <h4>Win/Loss/Draw (Improved Model)</h4>

      <p>Training Classification Accuracy: 57%</p>
      <p>Test Classification Accuracy: 55%</p>

      <h4>Win/Loss/Draw (Best Model)</h4>

      <p>Training Classification Accuracy: 66%</p>
      <p>Test (World Cup 2018 dataset) Classification Accuracy: 61.5%</p>

      <hr>

    </div> <!-- /col-md-10 -->
    </div> <!-- /row -->
    </div> <!-- /container -->
  </body>
</html>
